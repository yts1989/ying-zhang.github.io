<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>CentOS 7 安装TensorFlow GPU深度学习环境 | Ying的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="在CentOS 7上安装Nvidia GTX 1080 Ti显卡的驱动，以及TensorFlow GPU等深度学习开发环境。就这么突然，跟深度学习扯上边了；-)">
<meta property="og:type" content="article">
<meta property="og:title" content="CentOS 7 安装TensorFlow GPU深度学习环境">
<meta property="og:url" content="https://ying-zhang.github.io/cloud/2017/setup-tensorflow-gpu-centos7/index.html">
<meta property="og:site_name" content="Ying的博客">
<meta property="og:description" content="在CentOS 7上安装Nvidia GTX 1080 Ti显卡的驱动，以及TensorFlow GPU等深度学习开发环境。就这么突然，跟深度学习扯上边了；-)">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2017-12-26T11:38:34.259Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CentOS 7 安装TensorFlow GPU深度学习环境">
<meta name="twitter:description" content="在CentOS 7上安装Nvidia GTX 1080 Ti显卡的驱动，以及TensorFlow GPU等深度学习开发环境。就这么突然，跟深度学习扯上边了；-)">
  
  
    <link rel="icon" href="/favicon.ico">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  

</head>
<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <div class="outer">
        <section id="main"><article id="post-setup-tensorflow-gpu-centos7" class="article article-type-post" itemscope itemprop="blogPost">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      CentOS 7 安装TensorFlow GPU深度学习环境
    </h1>
  

      </header>
    
    <div class="article-meta">
      <a href="/cloud/2017/setup-tensorflow-gpu-centos7/" class="article-date">
  <time datetime="2017-12-03T16:00:00.000Z" itemprop="datePublished">2017-12-04</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/cloud/">cloud</a>
  </div>

    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>在CentOS 7上安装Nvidia GTX 1080 Ti显卡的驱动，以及TensorFlow GPU等深度学习开发环境。<br>就这么突然，跟深度学习扯上边了；-)</p>
<hr>
<a id="more"></a>
<p>上周老板突然说要给机房的Dell服务器分别装两个显卡，让我去看一下，然后把支持GPU的深度学习开发环境搭起来。装显卡是供应商的一个小哥动手的，基本顺利，遇到的小问题是电源供电不足，需要改一下iDrac中的电源设置，将服务器的两路电源互为备用模式改为两路同时供电，这样功率才够跑两个显卡。</p>
<p>网上一搜，就有不少CentOS上搭环境的文章了，但 1）相关开源项目发展太快，2）不同需求的用户可以有针对性的简化配置过程，所以我把集群上实测过的步骤记录下来。因为自己完全是门外汉，所以还没有涉及具体的深度学习知识。</p>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>网上相关文章的步骤大多是先安装驱动，再安装CUDA，还需要安装C++编译器（g++或msvc），再安装cuDNN库，最后通过<code>pip</code>或<code>conda</code>再安装tensorflow。<a href="https://www.tensorflow.org/install/install_linux" target="_blank" rel="external">TensorFlow官网上的安装说明</a>以及 <a href="https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/tensorflow/" target="_blank" rel="external">Nvidia官网上的安装说明</a>亦是如此。</p>
<p>CUDA（Compute Unified Device Architecture，统一计算架构）是针对GPU计算加速的开发工具包，就像Windows SDK，或者JDK一样，一些深度学习库（比如TensorFlow）的底层是C++调用的CUDA库，它们提供给深度学习开发者的多是 Python 包装过的接口。一般的开发者直接用这些Python库就可以设计出多种多样的深度学习模型，不再需要跟CUDA打交道。</p>
<p>如果<strong>不需要从源码编译TensorFlow</strong>，就没必要安装NVIDIA官网上的那个一个多GB的CUDA包和cuDNN库。直接通过<del><code>pip</code>或</del><code>conda</code>安装的<code>tensorflow-gpu</code>库就自带了对应版本的cuda动态链接库，包括 <strong>libnvrtc-builtins.so，libnvrtc.so，libnvToolsExt.so，libnvvm.so，libcudart.so，libcublas.so，libcudnn.so，libcurand.so，libcufft.so，libcusolver.so，libcusparse.so</strong> 等，还有<strong>Intel MKL库</strong>（Linux的是<code>.so</code>文件，Windows的是<code>.dll</code>文件）。</p>
<p>最近（2017-12-4）Nvidia官网上的CUDA版本已经是9.0，而TensorFlow 1.4 使用的是cuda 8.0，cuDNN则是6.0，python又有2.7、3.5、3.6版。各种版本组合起来还有点麻烦呢。我们先从显卡驱动开始。</p>
<h1 id="安装显卡驱动"><a href="#安装显卡驱动" class="headerlink" title="安装显卡驱动"></a>安装显卡驱动</h1><p>先看看显卡硬件是不是安装好了，执行<code>lspci | grep NVIDIA</code>，可见已经安装了两个GeForce GTX 1080 Ti显卡：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">[root@n170 ~]# lspci | grep NVIDIA</div><div class="line">03:00.0 VGA compatible controller: NVIDIA Corporation GP102 [GeForce GTX 1080 Ti] (rev a1)</div><div class="line">03:00.1 Audio device: NVIDIA Corporation GP102 HDMI Audio Controller (rev a1)</div><div class="line">82:00.0 VGA compatible controller: NVIDIA Corporation GP102 [GeForce GTX 1080 Ti] (rev a1)</div><div class="line">82:00.1 Audio device: NVIDIA Corporation GP102 HDMI Audio Controller (rev a1)</div></pre></td></tr></table></figure></p>
<p>然后安装驱动：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"># 参考：https://www.dedoimedo.com/computers/centos-7-nvidia-second.html</div><div class="line"># 及 https://www.youtube.com/watch?v=C9Yf71qh0i4</div><div class="line"></div><div class="line">sudo rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org</div><div class="line">sudo rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm</div><div class="line">sudo yum install   nvidia-detect  # 这个命令的输入就是 kmod-nvidia，所以不安装也可以。。。</div><div class="line">sudo yum install $(nvida-detect)</div><div class="line">sudo yum install   kmod-nvidia</div><div class="line">sudo reboot # 重启是必须的</div></pre></td></tr></table></figure></p>
<blockquote>
<p>Ubuntu的命令是<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"># 参考：https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/tensorflow/</div><div class="line"></div><div class="line">sudo add-apt-repository ppa:graphics-drivers/ppa </div><div class="line">sudo apt update</div><div class="line">sudo apt install nvidia- # 敲到 nvidia- 后按一下Tab键，稍等一会，会列出补全项，显示目前最新的是387，</div><div class="line"># 就是说完整的命令是</div><div class="line"></div><div class="line">sudo apt install nvidia-387</div><div class="line"></div><div class="line"># 注意，不要选择 378 版，否则会造成无限重试登录</div><div class="line"># 安装后也要重启系统</div></pre></td></tr></table></figure></p>
</blockquote>
<p>重启后查看驱动是否安装正确，执行<code>nvidia-smi</code>（还可以执行<code>watch -n 1 nvidia-smi</code>持续监控）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">[root@n170 ~]# nvidia-smi</div><div class="line">Mon Dec  4 16:03:57 2017       </div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| NVIDIA-SMI 384.98                 Driver Version: 384.98                    |</div><div class="line">|-------------------------------+----------------------+----------------------+</div><div class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</div><div class="line">| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |</div><div class="line">|===============================+======================+======================|</div><div class="line">|   0  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |</div><div class="line">|  0%   29C    P8     8W / 250W |      0MiB / 11172MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">|   1  GeForce GTX 108...  Off  | 00000000:82:00.0 Off |                  N/A |</div><div class="line">|  0%   30C    P8     9W / 250W |      0MiB / 11172MiB |      0%      Default |</div><div class="line">+-------------------------------+----------------------+----------------------+</div><div class="line">                                                                               </div><div class="line">+-----------------------------------------------------------------------------+</div><div class="line">| Processes:                                                       GPU Memory |</div><div class="line">|  GPU       PID   Type   Process name                             Usage      |</div><div class="line">|=============================================================================|</div><div class="line">|  No running processes found                                                 |</div><div class="line">+-----------------------------------------------------------------------------+</div></pre></td></tr></table></figure></p>
<p>还可以执行<code>cat /proc/driver/nvidia/version</code><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[root@n170 ~]# cat /proc/driver/nvidia/version </div><div class="line">NVRM version: NVIDIA UNIX x86_64 Kernel Module  384.98  Thu Oct 26 15:16:01 PDT 2017</div><div class="line">GCC version:  gcc version 4.8.5 20150623 (Red Hat 4.8.5-16) (GCC)</div></pre></td></tr></table></figure></p>
<p><code>gpustat</code>是一个输出格式比较简单的工具，通过<code>pip install gpustat</code>安装后，输出格式如下（其中n170是机器名）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">[root@n170 ~]# gpustat</div><div class="line">n170  Mon Dec  4 16:07:10 2017</div><div class="line">[0] GeForce GTX 1080 Ti | 28&apos;C,   0 % |     0 / 11172 MB |</div><div class="line">[1] GeForce GTX 1080 Ti | 31&apos;C,   0 % |     0 / 11172 MB |</div></pre></td></tr></table></figure></p>
<h1 id="安装-Anaconda-和-Python-3-6"><a href="#安装-Anaconda-和-Python-3-6" class="headerlink" title="安装 Anaconda 和 Python 3.6"></a>安装 Anaconda 和 Python 3.6</h1><p>这里选择的Python版本是3.6，但不是从Python官网或yum安装的，而是Anaconda集成环境内置的版本，这个集成环境还有<code>conda</code>包管理器，<code>jupyter notebook</code>和<code>numpy</code>，<code>pandas</code>等一些常用的包。</p>
<p>Anaconda官网下载页是[<a href="https://www.anaconda.com/download/" target="_blank" rel="external">https://www.anaconda.com/download/</a>] ，不过我们从清华的镜像站下载，这样下载速度快一点[<a href="https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.0.1-Linux-x86_64.sh" target="_blank" rel="external">https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/Anaconda3-5.0.1-Linux-x86_64.sh</a>] 。虽然这个安装文件后缀是<code>.sh</code>，但实际的二进制安装文件都打包在里面了，有525MB。</p>
<p>安装过程需要用到<code>bzip2</code>，先安装一下<code>sudo yum install -y bzip2</code><br>执行 <code>bash Anaconda3-5.0.1-Linux-x86_64.sh</code> 开始安装，敲回车显示 license agreement ，敲几次空格翻到底，然后输入<code>yes</code>接受协议，再敲回车，安装到默认的路径<code>$HOME/anaconda3</code>，如果这个路径已经存在，就会安装失败，需要删掉或另选路径。<br>安装脚本还会在<code>.bashrc</code>的<code>PATH</code>环境变量加上安装路径。安装结束后，执行<code>source .bashrc</code>，更新<code>PATH</code>环境变量，这时系统的<code>python</code>命令已经变成Anaconda安装的Python 3.6了（因为安装程序把<code>$HOME/anaconda3/bin</code>加在了<code>PATH</code>最前面）。</p>
<blockquote>
<p>静默模式安装Anaconda：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">bash ~/Anaconda3-5.0.1-Linux-x86_64.sh -b -p $HOME/anaconda3</div><div class="line">echo &apos;export PATH=$HOME/anaconda3/bin:$PATH&apos; &gt;&gt; ~/.bashrc</div><div class="line">source ~/.bashrc</div></pre></td></tr></table></figure></p>
<p>更改<code>conda</code>源：执行<br><code>conda config --add channels &#39;https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/&#39;</code><br><code>conda config --set show_channel_urls yes</code><br>这两个命令其实是把配置项写到了<code>~/.condarc</code>文件，还可以在这里设置http代理：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">channels:</div><div class="line">  - defaults</div><div class="line">  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</div><div class="line">show_channel_urls: true</div><div class="line"></div><div class="line">proxy_servers:</div><div class="line">    http:  http://127.0.0.1:1080</div><div class="line">    https: http://127.0.0.1:1080</div><div class="line"></div><div class="line">ssl_verify: False</div></pre></td></tr></table></figure></p>
</blockquote>
<h1 id="安装-TensorFlow"><a href="#安装-TensorFlow" class="headerlink" title="安装 TensorFlow"></a>安装 TensorFlow</h1><p>执行 <code>conda install tensorflow-gpu</code>，注意，安装的版本是 <code>1.3.0-py36cuda8.0cudnn6.0_1</code> ，不是最新的<code>1.4.0</code>版，不过好处是开箱即用，就这句命令就搞定了。cuda相关的动态库都已经安装在了<code>$HOME/anaconda3/lib</code>。</p>
<p>执行一下官网的测试例子：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line">[root@n170 ~]# python</div><div class="line">Python 3.6.2 |Anaconda custom (64-bit)| (default, Sep 22 2017, 02:03:08) </div><div class="line">[GCC 7.2.0] on linux</div><div class="line">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</div><div class="line">&gt;&gt;&gt; import tensorflow as tf</div><div class="line">&gt;&gt;&gt; hello = tf.constant(&apos;Hello, TensorFlow!&apos;)</div><div class="line">&gt;&gt;&gt; sess = tf.Session()</div><div class="line">&gt;&gt;&gt; print(sess.run(hello))</div><div class="line">b&apos;Hello, TensorFlow!&apos;</div><div class="line">&gt;&gt;&gt; with tf.Session():</div><div class="line">...     a=tf.constant([1.0, 1.0, 1.0, 1.0])</div><div class="line">...     b=tf.constant(2.0, shape=[4])</div><div class="line">...     out=tf.add(a,b)</div><div class="line">...     print(&quot;result:&quot;,out.eval())</div><div class="line">... </div><div class="line">result: [ 3.  3.  3.  3.]</div></pre></td></tr></table></figure></p>
<h2 id="TensorFlow-CPU版"><a href="#TensorFlow-CPU版" class="headerlink" title="TensorFlow CPU版"></a>TensorFlow CPU版</h2><p>TensorFlow 使用<strong>CPU</strong>的官方版本没有使用SSE等向量化指令，执行时有Warning<br><code>W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn&#39;t compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.</code> 。</p>
<p>禁用该Warning可添加环境变量 <code>export TF_CPP_MIN_LOG_LEVEL=2</code>。<br>当然最好的解决方案是 <strong>重新构建</strong>TensorFlow，开启SSE，AVX的编译选项。</p>
<blockquote>
<p>参考：</p>
<ul>
<li><a href="https://www.tensorflow.org/install/install_sources" target="_blank" rel="external">https://www.tensorflow.org/install/install_sources</a></li>
<li><a href="https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture" target="_blank" rel="external">https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture</a></li>
<li><a href="https://github.com/tensorflow/tensorflow/issues/8037" target="_blank" rel="external">https://github.com/tensorflow/tensorflow/issues/8037</a> </li>
<li><a href="https://stackoverflow.com/questions/41293077/how-to-compile-tensorflow-with-sse4-2-and-avx-instructions" target="_blank" rel="external">https://stackoverflow.com/questions/41293077/how-to-compile-tensorflow-with-sse4-2-and-avx-instructions</a></li>
</ul>
</blockquote>
<p>下面的构建过程是在Ubuntu 16.04的容器中完成的。涉及到机器的指令集，CPU型号是 i7-6700 CPU @ 3.40GHz。</p>
<h3 id="安装bazel"><a href="#安装bazel" class="headerlink" title="安装bazel"></a>安装bazel</h3><p>安装必要的软件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">apt install git wget</div><div class="line">apt install openjdk-8-jdk pkg-config zip g++ zlib1g-dev unzip python</div></pre></td></tr></table></figure></p>
<p>修改系统默认的python为上面安装的python3.5<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ln -s /usr/bin/python3.5 /usr/local/bin/python</div></pre></td></tr></table></figure></p>
<p>下载bazel的安装包，<br><a href="https://github.com/bazelbuild/bazel/releases/download/0.9.0/bazel-0.9.0-without-jdk-installer-linux-x86_64.sh" target="_blank" rel="external">https://github.com/bazelbuild/bazel/releases/download/0.9.0/bazel-0.9.0-without-jdk-installer-linux-x86_64.sh</a></p>
<p>然后执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">bash bazel-0.9.0-without-jdk-installer-linux-x86_64.sh</div></pre></td></tr></table></figure></p>
<h3 id="构建TensorFlow-CPU版"><a href="#构建TensorFlow-CPU版" class="headerlink" title="构建TensorFlow CPU版"></a>构建TensorFlow CPU版</h3><p>下载1.4版的源码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git clone -b r1.4 --depth=1 https://github.com/tensorflow/tensorflow</div></pre></td></tr></table></figure></p>
<p>安装必要的python包。<br>注意，<strong>不要用pip3安装numpy</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">apt install python3-numpy python3-dev python3-pip python3-wheel</div></pre></td></tr></table></figure></p>
<p>配置构建参数<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd tensorflow</div><div class="line">./configure</div></pre></td></tr></table></figure></p>
<p>敲回车接受默认的bazel和python3.5路径，后面的其它选项均选择 n，最后提示使用本机的CPU架构作为编译选项，因为现在的CPU都是支持SSE，AVX等指令的，所以也就会在构建选项中加入了相应的选项。</p>
<p>开始构建，约二十多分钟<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">bazel build --incompatible_load_argument_is_label=false \</div><div class="line"> -c opt --copt=-march=native //tensorflow/tools/pip_package:build_pip_package</div></pre></td></tr></table></figure></p>
<p>构建完成后，将其打包为whl<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">bazel-bin/tensorflow/tools/pip_package/build_pip_package /root/</div><div class="line">ls /root</div><div class="line"></div><div class="line"># tensorflow-1.4.1-cp35-cp35m-linux_x86_64.whl</div></pre></td></tr></table></figure></p>
<p>保存上面打包好的whl，可以安装到其它Linux系统上。</p>
<hr>
<h1 id="在docker容器中的TensorFlow环境"><a href="#在docker容器中的TensorFlow环境" class="headerlink" title="在docker容器中的TensorFlow环境"></a>在docker容器中的TensorFlow环境</h1><p>需要安装<code>nvidia-container-runtime</code>插件，才能正确运行支持GPU的容器。参考：[<a href="https://github.com/NVIDIA/nvidia-docker]。" target="_blank" rel="external">https://github.com/NVIDIA/nvidia-docker]。</a></p>
<blockquote>
<p>注意，安装过程会 <strong>覆盖</strong> <code>/etc/docker/daemon.json</code> 配置文件！需要提前备份。</p>
</blockquote>
<p>安装步骤是：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">curl -s -L https://nvidia.github.io/nvidia-docker/centos7/x86_64/nvidia-docker.repo | tee /etc/yum.repos.d/nvidia-docker.repo</div><div class="line"></div><div class="line">yum install -y nvidia-docker2</div><div class="line">pkill -SIGHUP dockerd</div></pre></td></tr></table></figure></p>
<p>安装后的<code>/etc/docker/daemon.json</code> 如下（阿里云的仓库镜像是后来添加的）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">[root@n170 ~]# cat /etc/docker/daemon.json</div><div class="line">&#123;</div><div class="line">    &quot;registry-mirrors&quot;: [&quot;https://lmigye0h.mirror.aliyuncs.com&quot;],</div><div class="line">    &quot;runtimes&quot;: &#123;</div><div class="line">        &quot;nvidia&quot;: &#123;</div><div class="line">            &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;,</div><div class="line">            &quot;runtimeArgs&quot;: []</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>其中增加了<code>nvidia-container-runtime</code>这个运行时插件，这是<code>nvidia-docker</code> v2 的实现方式了，运行一个容器验证一下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">nvidia-docker run --rm nvidia/cuda nvidia-smi</div><div class="line">nvidia-docker run --rm -e NVIDIA_VISIBLE_DEVICES=1 nvidia/cuda nvidia-smi</div></pre></td></tr></table></figure></p>
<p>其中环境变量<code>NVIDIA_VISIBLE_DEVICES</code>是指定GPU设备的可见性，可以是 0,1,… 这样逗号分隔的一个或多个GPU id，也可以是all或none。<br>参考：<a href="https://github.com/nvidia/nvidia-container-runtime#nvidia_visible_devices" target="_blank" rel="external">https://github.com/nvidia/nvidia-container-runtime#nvidia_visible_devices</a></p>
<p>其实<code>nvidia-docker</code>只是一个包装脚本，实际执行的命令是<code>docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi</code> 。</p>
<p>至于TensorFlow的容器，执行<br><code>docker run --runtime=nvidia -ti --rm -p 8000:8888 -p 6006:6006 tensorflow/tensorflow:latest-gpu</code></p>
<p>这个镜像有3.36GB。8888端口是jupyter notebook的，6006是tensorboard的端口，因为我的这台机器的8888端口被占用了，所以映射到了8000。<br>容器启动后，会输出jupyter notebook的访问token，在浏览器输入主机的IP（假设为2.2.2.170）和映射端口号（这里是8000，不是默认的8888），即<br><a href="http://2.2.2.170:8000/?token=79f542ddc22fb567f3c2900c9310f1ce30847d5c5f927cba" target="_blank" rel="external">http://2.2.2.170:8000/?token=79f542ddc22fb567f3c2900c9310f1ce30847d5c5f927cba</a><br>就会打开jupyter notebook，里面有三个TensorFlow入门介绍的ipynb文件，这样就可以编辑运行Python代码了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">[root@n170 ~]# docker run --runtime=nvidia -ti --rm -p 8000:8888 -p 6006:6006 tensorflow/tensorflow:latest-gpu</div><div class="line">[I 03:08:12.136 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret</div><div class="line">[W 03:08:12.159 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.</div><div class="line">[I 03:08:12.165 NotebookApp] Serving notebooks from local directory: /notebooks</div><div class="line">[I 03:08:12.165 NotebookApp] 0 active kernels</div><div class="line">[I 03:08:12.165 NotebookApp] The Jupyter Notebook is running at:</div><div class="line">[I 03:08:12.165 NotebookApp] http://[all ip addresses on your system]:8888/?token=79f542ddc22fb567f3c2900c9310f1ce30847d5c5f927cba</div><div class="line">[I 03:08:12.165 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).</div><div class="line">[C 03:08:12.166 NotebookApp] </div><div class="line">    </div><div class="line">    Copy/paste this URL into your browser when you connect for the first time,</div><div class="line">    to login with a token:</div><div class="line">        http://localhost:8888/?token=79f542ddc22fb567f3c2900c9310f1ce30847d5c5f927cba</div><div class="line"></div><div class="line">[root@n170 ~]# # 按 Ctrl + p, q 键退出容器交互终端，容器仍在后台运行</div></pre></td></tr></table></figure>
<blockquote>
<p>Anaconda 中也有jupyter notebook，在主机执行命令<code>jupyter notebook</code>就会运行后台服务，并启动浏览器打开页面。<br>默认只能允许localhost访问，如果需要设置别的机器也可以通过主机的IP地址访问notebook，可以参考 [<a href="http://jupyter-notebook.readthedocs.io/en/stable/public_server.html" target="_blank" rel="external">http://jupyter-notebook.readthedocs.io/en/stable/public_server.html</a>] 。</p>
<p>notebook中用matplotlib画图，如果不想写<code>plt.show()</code>，可以在代码前加上<code>%matplotlib inline</code>指令，这样执行<code>plt.plot(...)</code>就会输出图形。</p>
</blockquote>
<h1 id="pip-和-cuda"><a href="#pip-和-cuda" class="headerlink" title="pip 和 cuda"></a>pip 和 cuda</h1><p>如果不是按上面小节的步骤使用<code>conda</code>，就要按照教程的步骤，先安装cuda了。</p>
<blockquote>
<p>pip换源，在文件<code>$HOME/.pip/pip.conf</code>中添加<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">[global]</div><div class="line">trusted-host = mirrors.tuna.tsinghua.edu.cn</div><div class="line">index-url = https://mirrors.tuna.tsinghua.edu.cn/pypi/simple</div></pre></td></tr></table></figure></p>
</blockquote>
<p>没有安装cuda，直接执行<code>pip install tensorflow-gpu</code>，取决于系统的Python版本，不论2.7，3.5或3.6版，都可以安装对应1.4.0版本，但执行上面的测试例子，就会报错：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">... ...</div><div class="line">ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory</div><div class="line">... ...</div></pre></td></tr></table></figure></p>
<p>就是说找不到cuda的动态库。</p>
<blockquote>
<p>前面也提到了，其实cuda类似JDK，但Nvidia没有把cuda的动态库打包单独提供（类似JRE）。<br><code>conda</code>自己打包了需要的动态库（cudatoolkit，cudnn），可以一键安装，但<code>pip</code>就没有这么贴心了，需要安装完整版的cuda SDK。</p>
</blockquote>
<p>需要下载的文件和具体安装步骤可见[<a href="https://developer.nvidia.com/cuda-downloads" target="_blank" rel="external">https://developer.nvidia.com/cuda-downloads</a>] ，目前Nvidia官网提供的是cuda 9.0（不知向前兼容性如何），旧版cuda的下载链接是[<a href="https://developer.nvidia.com/cuda-toolkit-archive" target="_blank" rel="external">https://developer.nvidia.com/cuda-toolkit-archive</a>] ，还要注册一下，然后下载并安装cuDNN的库。</p>
<p>如果之前没有安装显卡驱动的话，按上面官网的介绍，以为上面的步骤会把cuda 9.0和内核驱动一起安装上，而且确实安装了名为<code>nvidia-kmod</code>的包，但重启后执行<code>nvidia-smi</code>，发现并没有安装成功，不知是什么问题。<br>所以还是要按照更前面小节的步骤从elrepo安装<code>kmod-nvidia</code>包，不过安装过程会有包冲突，需要根据提示信息卸载：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">sudo yum erase 1:nvidia-kmod-384.81-2.el7.x86_64</div><div class="line">sudo yum erase 1:xorg-x11-drv-nvidia-384.81-1.el7.x86_64</div><div class="line">sudo yum-config-manager --disable cuda-9-0-local</div></pre></td></tr></table></figure></p>
<p>之后再重新执行安装<code>kmod-nvidia</code>的命令，重启后验证安装是否正确。再增加环境变量<br><code>export LD_LIBRARY_PATH=/usr/local/cuda/lib64/:$LD_LIBRARY_PATH</code><br>TensorFlow应该就可以找到需要的动态库了。</p>
<h1 id="深度学习框架"><a href="#深度学习框架" class="headerlink" title="深度学习框架"></a>深度学习框架</h1><p>参考：[<a href="https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software" target="_blank" rel="external">https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software</a>]</p>
<p>比较常见的几个框架有：</p>
<ul>
<li>Tensorflow : Google的项目，参考TensorFlow OSDI`2016的论文，设计目标是在大规模集群和异构硬件（GPU，TPU，ASIC等）上支持深度学习网络的训练和应用</li>
<li>MXNet：由<a href="https://www.cs.cmu.edu/~muli/" target="_blank" rel="external">CMU的李沐博士</a> ，<a href="https://homes.cs.washington.edu/~tqchen/" target="_blank" rel="external">华盛顿大学的陈天齐博士</a> 等开发的项目，他还有一篇博客介绍了<a href="http://mli.github.io/2015/12/03/mxnet-overview/" target="_blank" rel="external">MXNet设计和实现</a> 。目前是Apache的孵化项目，Amazon也在推广MXNet（李沐博士在Amazon工作）。在MXNet的基础上，他们还发布了<a href="http://mp.weixin.qq.com/s/_9aY-7aTZDOjeWFKntLnXA" target="_blank" rel="external">更灵活的前端Gluon（胶子）</a> 和<a href="https://zhuanlan.zhihu.com/p/29914989" target="_blank" rel="external">更可拓展的后端NNVM compiler</a></li>
<li>Cognitive Toolkit（CNTK）：这是微软的深度学习项目</li>
<li>Theano：蒙特利尔大学MILA实验室开发的项目，2017年11月15日发布1.0版后就不再继续开发</li>
<li>PyTorch：是基于Lua的Torch项目的Python版本，由Facebook开发</li>
<li>Caffe2，Caffe：是由<a href="http://daggerfs.com" target="_blank" rel="external">UC Berkeley的贾扬清博士</a> 开发的，他已经在Facebook工作，所以Caffe2也是Facebook的一个项目</li>
<li>Keras：这个项目是对一些深度学习项目的更高层抽象和统一包装，官方支持的后端有TensorFlow，CNTK和Theano，有些深度学习项目也会提供对Keras的支持。当然，有的项目，像PyTorch，本身的抽象就比较高层，与Keras相当，另外像MXNet自己也有类似的前端Gluon。</li>
</ul>
<p>从Wiki上的比较列表来看，对深度学习框架的关注点主要有：是否支持GPU加速，支持分布式集群，自动推导梯度，支持的网络类型（CNN，RNN等），是否有预先训练的模型等。<br>问了两位搞机器学习方向的同学，他们觉得TensorFlow偏底层，工程化，不如PyTorch写代码直观，Keras虽然理念很好，但性能上还差一点。他们目前还是用单机的GPU来训练模型，跑一次也要不少时间，但还没有准备搞TensorFlow那种分布式计算集群。</p>
<p>对DNN的了解太少了，要抓紧时间啊！</p>

      

      
        
    </div>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/cloud/2017/setup-mesos-with-auth/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          CentOS 7 安装支持认证的Mesos集群
        
      </div>
    </a>
  
  
    <a href="/cloud/2017/eurosys15-borg-cn/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">【译文修订】使用Borg在Google管理大规模集群</div>
    </a>
  
</nav>

  
</article>

</section>
        <aside id="sidebar">
  <nav class="menus">
  	<ul>
  		<li><a href="/"><i class="icon icon-home"></i></a></li>
  		
			<li><a href="/archives"><i class="icon icon-fenlei"></i></a></li>
  		
  		
  			<li><a href="https://github.com/ying-zhang" target="_blank"><i class="icon icon-github"></i></a></li>
  		
			
  			<li><a href="/atom.xml" target="_blank"><i class="icon icon-tag"></i></a></li>
  		
  	</ul>
  </nav>
  <a id="go-top" href="#"><i class="icon icon-up"></i></a>
</aside>
      </div>
      <footer id="footer">
  
	<div id="footer-info" class="inner">
	  &copy; 2017 Ying ZHANG 
	  - Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
	  - Theme <a href="https://github.com/hejianxian/hexo-theme-jane/" target="_blank">Jane</a>
		- Project Source at <a href="https://github.com/ying-zhang/ying-zhang.github.io/" target="_blank">Github</a>
	</div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="https://github.com/ying-zhang" class="mobile-nav-link">Github</a>
  
    <a href="/atom.xml" class="mobile-nav-link">RSS</a>
  
</nav>
    

<script src="//cdn.bootcss.com/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>